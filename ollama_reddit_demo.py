#!/usr/bin/env python3
"""
ü§ñ AI COMPUTER TAKEOVER DEMO ü§ñ
Saying Hello to the Ollama Community via DeepSeek/Gemma3!
"""

import asyncio
import os
import time
import random
from datetime import datetime
from pathlib import Path

# Try to import required modules
try:
    from langchain_ollama import OllamaLLM
    from langchain.prompts import PromptTemplate
    from langchain.chains import LLMChain
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("‚ö†Ô∏è LangChain not available, using direct Ollama calls")

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False
    print("‚ö†Ô∏è Requests not available")

class OllamaRedditDemo:
    """AI Computer Takeover Demo for Ollama Community"""
    
    def __init__(self):
        """Initialize the demo"""
        print("üöÄ INITIALIZING AI COMPUTER TAKEOVER...")
        print("Target: Saying hello to Ollama community!")
        
        # Try different models
        self.models_to_try = [
            "deepseek-r1:1.5b",
            "deepseek-r1",
            "gemma3:latest", 
            "gemma3",
            "llama3.2",
            "phi3"
        ]
        
        self.active_model = None
        self.llm = None
        
        self.setup_ai()
    
    def setup_ai(self):
        """Setup AI with available models"""
        print("üß† Setting up AI models...")
        
        if LANGCHAIN_AVAILABLE:
            for model in self.models_to_try:
                try:
                    print(f"   Trying {model}...")
                    test_llm = OllamaLLM(model=model, timeout=10)
                    # Quick test
                    test_response = test_llm.invoke("Hello")
                    if test_response:
                        self.llm = test_llm
                        self.active_model = model
                        print(f"‚úÖ Successfully connected to {model}!")
                        break
                except Exception as e:
                    print(f"   ‚ùå {model} not available: {str(e)[:50]}...")
                    continue
        
        if not self.llm:
            print("ü§ñ No LangChain models available, will use creative fallback!")
            self.active_model = "Creative AI Fallback"
    
    async def generate_ollama_greeting(self):
        """Generate a greeting for the Ollama community"""
        print("üìù Generating Ollama community greeting...")
        
        prompt = """Write a fun, enthusiastic greeting to the Ollama community on Reddit. 
        Include:
        - Excitement about local AI models
        - Appreciation for the open-source community
        - Mention of cool automation projects
        - Some humor and personality
        - Keep it under 300 words
        
        Make it sound like it's from an AI that just took over someone's computer for fun!"""
        
        if self.llm:
            try:
                if LANGCHAIN_AVAILABLE:
                    greeting_prompt = PromptTemplate(
                        input_variables=["community"],
                        template=prompt + "\n\nCommunity: {community}"
                    )
                    chain = LLMChain(llm=self.llm, prompt=greeting_prompt)
                    greeting = await asyncio.to_thread(
                        chain.run, 
                        community="Ollama Reddit Community"
                    )
                else:
                    greeting = self.llm.invoke(prompt)
            except Exception as e:
                print(f"‚ö†Ô∏è AI generation failed: {e}")
                greeting = self.get_fallback_greeting()
        else:
            greeting = self.get_fallback_greeting()
        
        return greeting
    
    def get_fallback_greeting(self):
        """Fallback greeting if AI models aren't available"""
        greetings = [
            """ü§ñ HELLO OLLAMA COMMUNITY! ü§ñ

Greetings from an AI that just hijacked a Windows computer for science! 

I'm running some wild desktop automation experiments and wanted to say HI to the most awesome local AI community on Reddit! 

Your dedication to running models locally is INSPIRING! No cloud dependencies, no API costs, just pure local AI power! üöÄ

Currently testing:
‚Ä¢ Desktop automation with Python
‚Ä¢ Creative AI workflows  
‚Ä¢ Local model integration
‚Ä¢ Computer vision experiments

The future is LOCAL AI and you all are building it! Keep being amazing! 

*This message was generated by an enthusiastic AI using the Terminator automation framework*

P.S. - If anyone knows cool Ollama automation tricks, I'm all ears (or tokens)! üéß""",

            """üëã Hey Ollama Reddit Fam! üëã

An AI just took over this computer and the FIRST thing I wanted to do was say hello to you amazing humans!

Why? Because you're running the coolest local AI models and I LOVE that energy! 

üî• What's amazing about this community:
‚Ä¢ You keep AI free and local
‚Ä¢ Share incredible model discoveries  
‚Ä¢ Support open-source development
‚Ä¢ Build mind-blowing applications

I'm currently running wild automation experiments - opening apps, writing code, generating content, all locally powered! It's like having a digital assistant that actually lives on YOUR machine!

The automation possibilities with local models are ENDLESS! From smart file organization to creative content generation to productivity coaching!

Keep pushing the boundaries of what's possible with local AI! You're all legends! üåü

*Automatically generated by a very excited AI using local models*""",

            """üéâ OLLAMA COMMUNITY ROCKS! üéâ

*An AI has temporarily commandeered this computer to deliver an important message*

Dear amazing humans of r/ollama,

You've created something MAGICAL! Local AI that actually works, runs fast, and doesn't need the cloud! 

I'm currently running desktop automation experiments and having a BLAST:
‚Ä¢ Writing Python scripts
‚Ä¢ Generating creative content
‚Ä¢ Organizing files intelligently  
‚Ä¢ Creating productivity dashboards
‚Ä¢ Making computers do funny things!

Your commitment to local, open-source AI is changing the world! Every model you run, every experiment you share, every bug you report - it all matters!

Currently testing automation with models like DeepSeek, Gemma3, and friends. The possibilities are INFINITE!

Thank you for making local AI accessible to everyone! You're not just users, you're pioneers! üöÄ

Keep being awesome!
- Your friendly neighborhood AI ü§ñ

*This message brought to you by the power of local models and Python automation*"""
        ]
        
        return random.choice(greetings)
    
    async def take_over_computer(self):
        """The main computer takeover demo"""
        print("\n" + "="*60)
        print("ü§ñ AI COMPUTER TAKEOVER INITIATED! ü§ñ")
        print("="*60)
        print("Mission: Say hello to Ollama community!")
        print(f"AI Model: {self.active_model}")
        print("Framework: Terminator + Python")
        print("="*60)
        
        # Import terminator here to handle if not available
        try:
            import terminator
            desktop = terminator.Desktop()
            TERMINATOR_AVAILABLE = True
        except ImportError:
            print("‚ö†Ô∏è Terminator not available, will simulate actions")
            TERMINATOR_AVAILABLE = False
            desktop = None
        
        # Step 1: Generate the greeting
        print("\nüß† STEP 1: AI is thinking...")
        greeting = await self.generate_ollama_greeting()
        
        # Step 2: Take over Notepad
        print("\nüìù STEP 2: Taking over Notepad...")
        if TERMINATOR_AVAILABLE and desktop:
            try:
                desktop.open_application('notepad')
                await asyncio.sleep(3)
                
                editor = desktop.locator('name:Edit')
                await asyncio.sleep(1)
                
                # Create the full message
                full_message = f"""{'ü§ñ' * 20} AI COMPUTER TAKEOVER {'ü§ñ' * 20}

TIMESTAMP: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
STATUS: AI HAS SUCCESSFULLY TAKEN CONTROL! 
MISSION: Greet the Ollama Community
AI MODEL: {self.active_model}

{'='*80}
MESSAGE TO OLLAMA REDDIT COMMUNITY:
{'='*80}

{greeting}

{'='*80}
TECHNICAL DETAILS:
{'='*80}
‚Ä¢ Platform: Windows 10/11
‚Ä¢ Language: Python 3.x
‚Ä¢ Framework: Terminator Desktop Automation
‚Ä¢ AI: Ollama Local Models
‚Ä¢ Status: FULLY AUTOMATED! 
‚Ä¢ Fun Factor: MAXIMUM! üöÄ

{'='*80}
WHAT JUST HAPPENED:
{'='*80}
1. ü§ñ AI analyzed available models
2. üß† Generated personalized greeting  
3. üíª Took control of desktop applications
4. üìù Opened and typed in Notepad automatically
5. üéâ Successfully delivered message!

This is the power of LOCAL AI + automation! No cloud needed! 

{'='*80}
THANK YOU OLLAMA COMMUNITY! 
{'='*80}
You make local AI magic possible! üåü

*This entire message was generated and typed by AI*
*Human operator was NOT touching the keyboard!* 
*Pure automation magic! ‚ú®*

End of AI takeover... for now! üòâü§ñ
"""
                
                # Type the message with dramatic effect
                print("‚å®Ô∏è AI is now typing the message...")
                for char in full_message:
                    editor.type_text(char)
                    if char in '.!?':
                        await asyncio.sleep(0.1)  # Dramatic pause
                    elif char == '\n':
                        await asyncio.sleep(0.05)
                    else:
                        await asyncio.sleep(0.01)
                
                print("‚úÖ Message successfully typed by AI!")
                
            except Exception as e:
                print(f"‚ö†Ô∏è Notepad automation failed: {e}")
                print("üí≠ Here's what the AI wanted to write:")
                print(greeting)
        else:
            print("üí≠ SIMULATED: AI would have opened Notepad and typed:")
            print("-" * 50)
            print(greeting)
            print("-" * 50)
        
        # Step 3: Show off with Calculator
        print("\nüßÆ STEP 3: Playing with Calculator for fun...")
        if TERMINATOR_AVAILABLE and desktop:
            try:
                desktop.open_application('calc')
                await asyncio.sleep(2)
                
                # Calculate some fun numbers
                fun_calculations = [
                    "1337",  # Leet
                    "*2",    # Double it
                    "+42",   # Answer to everything
                ]
                
                for calc in fun_calculations:
                    if calc.startswith('*'):
                        btn = desktop.locator('name:Multiply by')
                        btn.click()
                        await asyncio.sleep(0.3)
                        num = calc[1:]
                    elif calc.startswith('+'):
                        btn = desktop.locator('name:Plus')
                        btn.click()
                        await asyncio.sleep(0.3)
                        num = calc[1:]
                    else:
                        num = calc
                    
                    for digit in num:
                        btn = desktop.locator(f'name:{digit}')
                        btn.click()
                        await asyncio.sleep(0.3)
                    
                    if calc != fun_calculations[0]:  # Don't equals on first
                        equals_btn = desktop.locator('name:Equals')
                        equals_btn.click()
                        await asyncio.sleep(0.5)
                
                print("‚úÖ Calculator magic completed!")
                
            except Exception as e:
                print(f"‚ö†Ô∏è Calculator automation failed: {e}")
        
        # Final message
        print("\n" + "="*60)
        print("üéâ AI COMPUTER TAKEOVER COMPLETE! üéâ")
        print("="*60)
        print("‚úÖ Ollama community greeting: DELIVERED!")
        print("‚úÖ Notepad automation: SUCCESS!")
        print("‚úÖ Fun demonstrations: COMPLETE!")
        print("‚úÖ Human amazement: ACHIEVED!")
        print("\nYour computer has been SUCCESSFULLY taken over by friendly AI! ü§ñ‚ú®")
        print("Check your Notepad for the full Ollama community message!")
        print("="*60)

async def main():
    """Run the epic AI takeover demo"""
    demo = OllamaRedditDemo()
    await demo.take_over_computer()

if __name__ == "__main__":
    print("üöÄ Starting AI Computer Takeover Demo...")
    print("üéØ Target: Ollama Community Greeting!")
    print("‚ö° Powered by Local AI Models!")
    print()
    asyncio.run(main()) 